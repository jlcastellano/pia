<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Perfil del programador de inteligencia artificial</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <header>
        <div>Perfil del programador de inteligencia artificial</div>
    </header>

    <section class="contenido-didactico">
        <h1>3. Lenguajes de Programación</h1>

        <p>Los algoritmos en los que se basa la inteligencia artificial actual son principalmente planteamientos muy
            matemáticos, y por eso, se suele programar en lenguajes de programación que tengan una buena orientación
            hacia ese tipo de desarrollos. Hay lenguajes que son muy eficientes en cálculos matemáticos, pero si son de
            bajo o medio nivel, harán demasiado compleja y tediosa la programación de tareas como las que requiere la
            inteligencia artificial. Además, estos lenguajes no son adecuados para trabajar con estructuras grandes o
            dinámicas de datos, porque utilizan la memoria de forma menos eficiente que los de alto nivel. Por lo tanto,
            se van a utilizar casi siempre lenguajes de alto nivel, que son compilados o ejecutados por un intérprete.
        </p>

        <p>Por otro lado, las aplicaciones más orientadas a negocio suelen utilizar un tipo de lenguajes, como Python o
            Java, mientras que en el ámbito de la investigación o de la ingeniería, se utilizan otros como Matlab o su
            homólogo "open source" Octave. Dentro de una estrategia "Data Driven" o de negocio basado en los datos, será
            común la utilización del lenguaje R, aunque para inteligencia artificial es un poco limitado. Si estamos
            hablando de ejecución dentro de un dispositivo móvil o en web apps que lo necesitan, también podría
            utilizarse Javascript o Node.js. Y, aunque no es muy común, para aplicaciones de alto rendimiento, se
            recurre a C++.</p>

        <h2>3.1. Octave</h2>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-15.png" alt="Octave">
            <figcaption>Octave</figcaption>
        </figure>
        <p>GNU Octave es un lenguaje de programación científica, con una sintaxis muy orientada al cálculo matemático.
            Es parte del proyecto GNU, por lo que es de código abierto u "open source", y gratuito. Al mismo tiempo, es
            compatible con Matlab, por lo que constituye una alternativa muy interesante cuando hay que colaborar en
            proyectos en los que también se utiliza éste. Está escrito en C++ y tiene un intérprete propio, que se suele
            ejecutar en su propio IDE (Entorno de desarrollo integrado). Es compatible con otros programas GNU para
            enriquecer la parte gráfica.</p>

        <p>Su potencia en el planteamiento de cálculos matemáticos y sus herramientas de visualización 2D y 3D los han
            hecho muy adecuado para la investigación en el campo del machine learning y la optimización.</p>

        <p>En su propia web están las distintas opciones de descarga según el sistema operativo y puedes consultar
            cualquier duda en su wiki.</p>

        <h2>3.2. Python</h2>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-16.png" alt="Python">
            <figcaption>Python</figcaption>
        </figure>
        <p>Python es un lenguaje de programación de propósito general muy sencillo y fácil de aprender, pero al mismo
            tiempo es muy potente y versátil, por lo que se ha extendido bastante en el ámbito académico y científico.
        </p>

        <p>Una de sus principales ventajas es que, además de POO (Programación Orientada a Objetos), también ofrece
            programación estructurada y funcional, que es un paradigma que va cogiendo fuerza y aceptación con los
            nuevos desarrollos de la industria actual. Se adapta al sistema operativo en el que se quiera utilizar y
            cuenta con un extensísimo catálogo de librerías creadas y mantenidas por la comunidad.</p>

        <p>Pero su normalización en el ámbito de la inteligencia artificial, ha tenido bastante que ver con la
            liberación del código de la librería TensorFlow por parte de Google. Esta librería estaba escrita en Python,
            lo que dio una ventaja especial a la comunidad de este lenguaje de programación, que se aceleró después y
            que ha contado con la contribución de multitud de proyectos de investigación en este campo de estudio desde
            un marco académico y científico.</p>

        <p>El objetivo principal de este lenguaje es su legibilidad, es decir, que sea un lenguaje fácil e intuitivo,
            que se entienda casi como cualquier texto en inglés. Pero, por otro lado, se le intenta dar toda la potencia
            del resto de lenguajes de su nivel, apto para programar rápidamente tareas sencillas o construir prototipos
            en poco tiempo. Es un proyecto de código abierto, lo cual ha sido determinante de cara a su adopción y
            evolución. Su capacidad para ser "incrustado" en otros programas escritos en C y C++ también lo hacen
            especialmente útil y aceptado en proyectos grandes.</p>

        <h3>Nuevos frameworks</h3>

        <ul>
            <li>JAX (Google)</li>
            <li>PyTorch 2.0+</li>
            <li>Transformers avanzados</li>
            <li>Mejoras en procesamiento paralelo</li>
            <li>Integración con IA generativa</li>
        </ul>

        <h2>3.3. R</h2>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-17.png" alt="R">
            <figcaption>R</figcaption>
        </figure>
        <p>R es un entorno de software libre y lenguaje de programación interpretado, sin necesidad de compilación. Se
            integra bien con otros lenguajes de programación como C o Fortran, lo que le permite la ejecución de tareas
            de análisis de datos muy voluminosas o intensivas. No es tanto un lenguaje para un código estático sino más
            bien unas instrucciones para generar un informe final, que es lo que realmente se busca.</p>

        <p>R también es un lenguaje de propósito general, pero sus librerías y paquetes se han centrado más en cálculo
            estadístico, visualización y flujo de datos en general. Cuenta con un repositorio centralizado de paquetes,
            denominado CRAN, que facilita bastante la programación de tareas de analítica de datos y lo que se conoce
            como "Big Data" o "Smart Data". Más que un lenguaje para programación de inteligencia artificial, podemos
            decir que se trata de un lenguaje auxiliar o complementario para parte de un proyecto integral en el que
            tengamos que atender al proceso completo desde la adquisición de datos hasta la obtención de predicciones y
            su presentación en una interfaz o aplicación, en el que el motor de inteligencia artificial se habrá
            generado y se ejecutará muy probablemente en otro lenguaje.</p>

        <h3>Nuevas capacidades</h3>

        <ul>
            <li>Integración con LLMs</li>
            <li>Visualización en tiempo real</li>
            <li>Procesamiento de datos no estructurados</li>
        </ul>

        <h2>3.4. Java</h2>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-18.png" alt="Java">
            <figcaption>Java</figcaption>
        </figure>
        <p>Podríamos decir que Java es el lenguaje de programación de la industria. Es el más utilizado en proyectos de
            negocio, en plataformas y herramientas de gestión. Pero a medida que la programación de inteligencia
            artificial y modelos de machine learning ha ido evolucionando hacia el paradigma de la programación
            funcional, Java, que es un lenguaje con una fuerte base en la POO (Programación Orientada a Objetos), va
            dejando de ser utilizado por una nueva generación de desarrolladores en este campo. Sin embargo, los
            desarrolladores que están acostumbrados a programar otro tipo de aplicaciones y que lo conocen muy bien, a
            la hora de programar inteligencia artificial, prefieren utilizar los recursos disponibles en este framework
            antes que iniciarse en Python.</p>

        <p>Este lenguaje de programación permite un mayor control del hardware, y su JVM (Java Virtual Machine) soporta
            la ejecución de otros lenguajes adaptados desde sus originales. Por ejemplo, Jython es el lenguaje JVM
            adaptado desde Python. Otra ventaja es que se puede ejecutar en cualquier arquitectura.</p>

        <h2>3.5. Otros</h2>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-19.png" alt="JavaScript">
            <figcaption>JavaScript</figcaption>
        </figure>
        <p>Hay desarrollos de inteligencia artificial en otros lenguajes de programación. Por ejemplo, aunque Javascript
            es considerado el lenguaje de programación de la web, existen librerías y herramientas que permiten ejecutar
            algoritmos de machine learning en aplicaciones, corriendo en Javascript o en sus frameworks más utilizados,
            como Node.js.</p>

        <h3>JavaScript/TypeScript</h3>

        <ul>
            <li>TensorFlow.js 4.0</li>
            <li>WebML</li>
            <li>Edge Computing para IA</li>
            <li>Frameworks para IA en navegador</li>
        </ul>

        <p>También es posible encontrar desarrollo de inteligencia artificial programados en C y en C++. Este lenguaje,
            además de ser la base de otros lenguajes de alto nivel que se usan en el campo del machine learning, cuenta
            con librerías muy potentes para aplicaciones que requieren de rapidez y rendimiento.</p>

        <blockquote>
            <strong>Para saber más:</strong> TensorFlow.js es una librería que permite desarrollar modelos de "machine
            learning" en Javascript para poder ejecutarlos directamente en el navegador o en Node.js. Cuenta con modelos
            de aprendizaje automático ya listos para usar, pero sobre todo es interesante convertir modelos que
            originalmente estaban en Python y ejecutarlos en entornos de JS. Para proyectos nuevos, también cuenta con
            todas las opciones para crear y entrenar desde cero cualquier modelo, utilizando las API disponibles.
        </blockquote>

        <h3>Nuevos Lenguajes y Frameworks relevantes</h3>

        <h4>Julia</h4>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-21.png" alt="Julia">
            <figcaption>Julia</figcaption>
        </figure>
        <p>Julia es un lenguaje de programación diseñado específicamente para resolver el dilema histórico de la
            computación científica: elegir entre lenguajes fáciles pero lentos (Python, R) o rápidos pero complejos (C,
            Fortran). Lanzado en 2012, Julia ofrece "velocidad de C con la conveniencia de Python", logrando
            rendimientos entre 10 y 100 veces más rápidos que Python en cálculos numéricos, mientras mantiene una
            sintaxis clara y natural. Su compilación Just-In-Time (JIT) mediante LLVM y su implementación nativa de
            álgebra lineal eliminan la necesidad de bibliotecas externas en C/C++, algo que Python requiere
            constantemente.</p>

        <p>El ecosistema de Julia para IA está creciendo con frameworks como Flux.jl (deep learning), MLJ.jl (machine
            learning) y Turing.jl (inferencia bayesiana), todos aprovechando la diferenciación automática nativa del
            lenguaje. Su verdadero potencial brilla en aplicaciones científicas avanzadas, particularmente en
            computación cuántica aplicada a IA con proyectos como Yao.jl. Aunque su adopción industrial está por detrás
            de Python, Julia gana tracción en investigación académica, laboratorios y sectores donde el rendimiento es
            crítico: finanzas cuantitativas, modelado climático y descubrimiento de fármacos mediante IA.</p>

        <h4>Rust para IA</h4>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-20.png" alt="Rust">
            <figcaption>Rust</figcaption>
        </figure>
        <p>Rust ha emergido como lenguaje fundamental para componentes de IA en producción donde seguridad, rendimiento
            y confiabilidad son críticos. Diseñado por Mozilla Research (2015), ofrece control de bajo nivel comparable
            a C++ pero con garantías de seguridad de memoria en tiempo de compilación, eliminando bugs catastróficos
            como desbordamientos de buffer, carreras de datos y punteros nulos. Esta combinación lo hace ideal para
            infraestructura ML que debe ser extremadamente rápida y absolutamente confiable, encontrando su nicho en
            runtimes de inferencia de alto rendimiento, sistemas embebidos, edge computing y servidores de modelos que
            procesan millones de predicciones por segundo.</p>

        <p>El ecosistema Rust para IA está madurando con frameworks como candle (Hugging Face) y tract, ofreciendo
            rendimiento comparable a PyTorch con garantías de seguridad superiores. Su interoperabilidad con Python
            mediante PyO3 permite a científicos de datos mantener workflows en Python mientras aceleran componentes
            críticos en Rust, obteniendo mejoras de 10-100x en rendimiento. Empresas como Hugging Face están
            reescribiendo componentes clave (tokenizers) en Rust por estas razones. A medida que la IA se despliega en
            sistemas críticos (médicos, financieros, seguridad), Rust se posiciona como el lenguaje que garantiza
            sistemas rápidos y seguros, cumpliendo un rol complementario pero esencial junto a Python en el stack
            moderno de IA.</p>
        <figure>
            <img src="prg-ia-01-08.png" alt="Frameworks de IA">
            <figcaption>Frameworks de IA</figcaption>
        </figure>
        <h2>3.6. Nuevas Tendencias en Desarrollo de Software e IA</h2>

        <h3>3.6.1. Multi-lenguaje: La Era de la Diversidad Tecnológica</h3>

        <p>El desarrollo multi-lenguaje ha evolucionado significativamente más allá de la simple coexistencia de
            diferentes tecnologías en un mismo proyecto. Actualmente, estamos presenciando una revolución en la forma en
            que los equipos aprovechan las fortalezas específicas de cada lenguaje de programación dentro de
            arquitecturas cohesivas y bien integradas.</p>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-09.png" alt="Multi-lenguaje">
            <figcaption>Multi-lenguaje</figcaption>
        </figure>
        <p>La interoperabilidad mejorada se ha convertido en un pilar fundamental de esta tendencia. Las organizaciones
            ya no se ven forzadas a estandarizar todo su stack tecnológico en un único lenguaje. En cambio, pueden
            seleccionar Python para tareas de ciencia de datos y machine learning, donde su ecosistema de bibliotecas
            como TensorFlow y PyTorch brilla con luz propia, mientras utilizan Go para servicios de alto rendimiento que
            requieren concurrencia eficiente, y JavaScript para el frontend y ciertas funcionalidades backend.
            Frameworks modernos como gRPC y GraphQL facilitan esta comunicación entre servicios escritos en diferentes
            lenguajes, permitiendo que cada componente del sistema utilice la herramienta más adecuada para su propósito
            específico.</p>

        <p>Los microservicios en diferentes lenguajes representan la materialización práctica de esta filosofía. Un
            mismo producto puede tener su motor de recomendaciones escrito en Python, su sistema de autenticación en
            Rust por razones de seguridad y rendimiento, su API gateway en Node.js para manejar conexiones concurrentes,
            y sus servicios de procesamiento de datos en Java aprovechando la madurez del ecosistema empresarial. Esta
            heterogeneidad, lejos de ser un problema, se convierte en una ventaja competitiva cuando se gestiona
            adecuadamente con herramientas de orquestación y observabilidad que trascienden las barreras del lenguaje.
        </p>

        <p>Las APIs unificadas actúan como el pegamento que mantiene cohesionado este ecosistema diverso. Los estándares
            como OpenAPI permiten documentar y consumir servicios independientemente del lenguaje en que estén
            implementados, mientras que las capas de abstracción proporcionadas por service meshes como Istio garantizan
            comportamientos consistentes en aspectos como seguridad, monitoreo y gestión del tráfico, sin importar la
            tecnología subyacente de cada servicio.</p>

        <h3>3.6.2. Desarrollo Low-Code/No-Code: Democratizando la Creación de Software</h3>

        <p>El movimiento low-code y no-code ha madurado hasta convertirse en una alternativa legítima para el desarrollo
            de aplicaciones complejas, especialmente cuando se combina con inteligencia artificial. Esta tendencia no
            busca reemplazar a los desarrolladores tradicionales, sino ampliar quién puede participar en la creación de
            soluciones tecnológicas y acelerar drásticamente los ciclos de desarrollo.</p>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-11.png" alt="Desarrollo Low-Code/No-Code">
            <figcaption>Desarrollo Low-Code/No-Code</figcaption>
        </figure>
        <p>Las plataformas visuales de IA representan uno de los avances más significativos en este espacio.
            Herramientas como Google Vertex AI, Azure ML Studio y Amazon SageMaker Canvas permiten a usuarios sin
            conocimientos profundos de programación construir, entrenar y desplegar modelos de machine learning mediante
            interfaces visuales intuitivas. Los usuarios pueden conectar bloques que representan diferentes etapas del
            pipeline de ML, desde la ingesta de datos hasta el entrenamiento del modelo y su despliegue, todo a través
            de drag-and-drop. Esto ha abierto las puertas para que analistas de negocio, científicos de dominio y otros
            profesionales puedan crear soluciones de IA que antes requerían equipos especializados.</p>

        <p>La automatización de ML, conocida como AutoML, lleva esta democratización un paso más allá. Estas
            herramientas no solo simplifican la interfaz, sino que automatizan decisiones técnicas complejas como la
            selección de algoritmos, la optimización de hiperparámetros y la ingeniería de características. Plataformas
            como H2O.ai, DataRobot y las capacidades AutoML de los principales proveedores cloud pueden evaluar
            automáticamente múltiples arquitecturas de modelos, realizar validación cruzada y seleccionar la mejor
            solución según métricas definidas por el usuario. Esto reduce el tiempo de desarrollo de modelos de semanas
            a horas, permitiendo iteraciones más rápidas y experimentación más ágil.</p>

        <p>Las interfaces drag-and-drop han evolucionado más allá de simples constructores de UI. Plataformas modernas
            como OutSystems, Mendix y Microsoft Power Platform ofrecen capacidades completas de desarrollo de
            aplicaciones empresariales, incluyendo lógica de negocio compleja, integraciones con sistemas legacy, y
            flujos de trabajo sofisticados. Los desarrolladores ciudadanos pueden crear aplicaciones funcionales que se
            conectan a APIs, procesan datos en tiempo real y proporcionan experiencias de usuario ricas, todo sin
            escribir código tradicional. Para desarrolladores profesionales, estas plataformas ofrecen puntos de
            extensión donde pueden inyectar código personalizado cuando se necesita funcionalidad específica que va más
            allá de las capacidades de la plataforma.</p>

        <h3>3.6.3. Cloud-Native Development: Arquitecturas Nacidas para la Nube</h3>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-12.png" alt="Cloud-Native Development">
            <figcaption>Cloud-Native Development</figcaption>
        </figure>
        <p>El desarrollo cloud-native ha evolucionado de ser una palabra de moda a convertirse en el estándar de facto
            para aplicaciones modernas, especialmente aquellas que incorporan componentes de inteligencia artificial y
            machine learning. Esta aproximación implica diseñar aplicaciones específicamente para aprovechar las
            características únicas de los entornos cloud.</p>

        <p>Kubernetes para IA ha emergido como la columna vertebral de la infraestructura de machine learning en
            producción. A diferencia del desarrollo tradicional, los workloads de IA presentan desafíos únicos como la
            necesidad de GPUs para entrenamiento, gestión de modelos versioned, y patrones de escalado complejos que
            difieren entre entrenamiento e inferencia. Kubernetes, con extensiones como Kubeflow, proporciona
            abstracciones para gestionar estos desafíos de manera declarativa. Los científicos de datos pueden definir
            pipelines completos de ML como código, incluyendo el aprovisionamiento de recursos computacionales
            específicos, orquestación de experimentos paralelos, y despliegue gradual de nuevas versiones de modelos.
            Operadores especializados como el NVIDIA GPU Operator facilitan la gestión eficiente de hardware acelerado,
            mientras que herramientas como KServe estandarizan el serving de modelos con capacidades avanzadas como A/B
            testing y canary deployments.</p>
        <figure style="float: right; width: 40%; margin: 0 0 1em 1em;">
            <img src="prg-ia-01-13.png" alt="MLOps">
            <figcaption>MLOps</figcaption>
        </figure>
        <p>Serverless AI representa un cambio de paradigma en cómo pensamos sobre el despliegue y escalado de modelos de
            machine learning. En lugar de gestionar clusters permanentes de servidores, los desarrolladores pueden
            desplegar funciones de inferencia que escalan automáticamente desde cero hasta millones de peticiones,
            pagando solo por el tiempo de computación utilizado. Servicios como AWS Lambda con contenedores, Google
            Cloud Functions y Azure Functions soportan ahora workloads de ML con tiempos de arranque optimizados y
            soporte para frameworks populares. Esto es particularmente valioso para casos de uso con patrones de tráfico
            impredecibles o esporádicos, donde mantener infraestructura dedicada sería ineficiente. Además, plataformas
            como AWS SageMaker Serverless Inference abstraen completamente la gestión de infraestructura, permitiendo a
            los equipos enfocarse puramente en la lógica del modelo.</p>

        <p>MLOps integrado cierra el círculo del desarrollo cloud-native al incorporar prácticas de DevOps
            específicamente adaptadas para machine learning. Mientras DevOps tradicional se enfoca en el código de
            aplicación, MLOps debe gestionar la complejidad adicional de datos, modelos y experimentos. Plataformas
            modernas integran control de versiones no solo para código sino también para datasets y modelos entrenados,
            utilizando herramientas como DVC y MLflow. La integración continua se extiende para incluir validación
            automática de modelos, detección de drift en datos, y pruebas de rendimiento del modelo. El despliegue
            continuo incorpora estrategias específicas de ML como shadow deployments, donde nuevos modelos procesan
            tráfico real sin afectar a los usuarios, permitiendo validación exhaustiva antes del rollout completo. Todo
            esto se orquesta mediante pipelines declarativos que pueden ejecutarse en cualquier entorno cloud-native,
            garantizando reproducibilidad y trazabilidad completa del ciclo de vida del modelo.</p>

    </section>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script
        src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
    <script src="script.js"></script>
</body>

</html>