{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios Prácticos: Optimización de Hiperparámetros\n",
    "\n",
    "Este notebook contiene ejercicios para practicar el uso de las principales herramientas de optimización de hiperparámetros en Deep Learning.\n",
    "\n",
    "**Instrucciones generales:**\n",
    "- Lee cuidadosamente cada enunciado antes de comenzar\n",
    "- Completa el código en las celdas indicadas\n",
    "- Ejecuta las celdas de verificación cuando estén disponibles\n",
    "- Los ejercicios están ordenados por dificultad creciente\n",
    "\n",
    "**Datasets utilizados:**\n",
    "- MNIST (dígitos manuscritos)\n",
    "- Fashion MNIST (prendas de ropa)\n",
    "- CIFAR-10 (imágenes a color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de dependencias\n",
    "!pip install keras-tuner optuna \"ray[tune]\" plotly -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones comunes\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Silenciar warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 1: Keras Tuner\n",
    "\n",
    "### Ejercicio 1.1: Búsqueda Básica de Hiperparámetros\n",
    "\n",
    "**Objetivo:** Familiarizarse con la sintaxis básica de Keras Tuner.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Tienes un modelo simple para clasificar el dataset Fashion MNIST. Tu tarea es modificar la función `build_model` para que Keras Tuner pueda buscar automáticamente:\n",
    "\n",
    "1. El número de neuronas en la capa oculta (entre 64 y 256, en pasos de 64)\n",
    "2. La tasa de dropout (entre 0.2 y 0.5, en pasos de 0.1)\n",
    "3. La tasa de aprendizaje (entre 0.001 y 0.01, usando escala logarítmica)\n",
    "\n",
    "**Pistas:**\n",
    "- Usa `hp.Int()` para valores enteros\n",
    "- Usa `hp.Float()` para valores decimales\n",
    "- El parámetro `sampling='log'` permite búsqueda en escala logarítmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(f\"Clases: {np.unique(y_train)}\")\n",
    "print(f\"Shape: {x_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    TODO: Completa esta función para que los hiperparámetros sean buscables.\n",
    "    \n",
    "    Hiperparámetros a buscar:\n",
    "    - units: número de neuronas (64 a 256, paso 64)\n",
    "    - dropout: tasa de dropout (0.2 a 0.5, paso 0.1)\n",
    "    - learning_rate: tasa de aprendizaje (0.001 a 0.01, escala log)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),\n",
    "        # TODO: Modificar la siguiente línea para buscar el número de unidades\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        # TODO: Modificar la siguiente línea para buscar el dropout\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # TODO: Modificar para buscar el learning rate\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura y ejecuta el tuner con RandomSearch\n",
    "# TODO: Crear un tuner con kt.RandomSearch\n",
    "# - objective: 'val_accuracy'\n",
    "# - max_trials: 10\n",
    "# - directory: 'ejercicio_1_1'\n",
    "# - project_name: 'fashion_mnist'\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecuta la búsqueda\n",
    "# TODO: Llamar a tuner.search() con:\n",
    "# - epochs=5\n",
    "# - validation_split=0.2\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra los mejores hiperparámetros\n",
    "# TODO: Obtener e imprimir los mejores hiperparámetros\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Ejercicio 1.2: Búsqueda de Arquitectura Variable\n",
    "\n",
    "**Objetivo:** Aprender a buscar arquitecturas con número variable de capas.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Crea un modelo donde Keras Tuner pueda decidir:\n",
    "\n",
    "1. El número de capas ocultas (entre 1 y 4)\n",
    "2. Para cada capa:\n",
    "   - Número de neuronas (32, 64, 128, o 256)\n",
    "   - Función de activación ('relu' o 'tanh')\n",
    "3. Si usar o no BatchNormalization después de cada capa densa\n",
    "\n",
    "**Pistas:**\n",
    "- Usa `hp.Choice()` para seleccionar de una lista de opciones\n",
    "- Usa `hp.Boolean()` para decisiones verdadero/falso\n",
    "- Usa un bucle `for` con `range(hp.Int(...))` para capas variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_variable_model(hp):\n",
    "    \"\"\"\n",
    "    TODO: Implementa un modelo con arquitectura variable.\n",
    "    \n",
    "    Hiperparámetros:\n",
    "    - num_layers: 1 a 4 capas\n",
    "    - units_i: neuronas por capa (32, 64, 128, 256)\n",
    "    - activation_i: función de activación ('relu', 'tanh')\n",
    "    - use_batchnorm: usar BatchNormalization (True/False)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "    \n",
    "    # TODO: Implementar la búsqueda de arquitectura variable\n",
    "    # Tu código aquí\n",
    "    \n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura un tuner con BayesianOptimization y ejecuta la búsqueda\n",
    "# TODO: Crear tuner, ejecutar búsqueda y mostrar resultados\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Ejercicio 1.3: Hyperband para Búsqueda Eficiente\n",
    "\n",
    "**Objetivo:** Utilizar el algoritmo Hyperband para búsquedas más eficientes.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "El algoritmo Hyperband es más eficiente que la búsqueda aleatoria porque asigna más recursos a las configuraciones prometedoras. Tu tarea es:\n",
    "\n",
    "1. Crear un modelo con los siguientes hiperparámetros buscables:\n",
    "   - Número de filtros en capas Conv2D (16, 32, 64)\n",
    "   - Tamaño del kernel (3 o 5)\n",
    "   - Usar o no MaxPooling después de cada Conv2D\n",
    "   - Número de neuronas en la capa densa (64 a 256)\n",
    "   - Learning rate (1e-4 a 1e-2)\n",
    "\n",
    "2. Configurar un tuner Hyperband con:\n",
    "   - `max_epochs=30`\n",
    "   - `factor=3` (factor de reducción)\n",
    "   - `hyperband_iterations=2`\n",
    "\n",
    "**Dataset:** MNIST reshapeado a (28, 28, 1) para usar Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para CNN\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "print(f\"Shape de entrenamiento: {x_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(hp):\n",
    "    \"\"\"\n",
    "    TODO: Implementa una CNN con hiperparámetros buscables.\n",
    "    \n",
    "    Hiperparámetros:\n",
    "    - filters: número de filtros (16, 32, 64)\n",
    "    - kernel_size: tamaño del kernel (3, 5)\n",
    "    - use_pooling: usar MaxPooling (True/False)\n",
    "    - dense_units: neuronas en capa densa (64 a 256, paso 32)\n",
    "    - learning_rate: tasa de aprendizaje (1e-4 a 1e-2, log)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # TODO: Implementar la CNN con hiperparámetros buscables\n",
    "    # Tu código aquí\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura y ejecuta el tuner Hyperband\n",
    "# TODO: Crear kt.Hyperband tuner y ejecutar búsqueda\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 2: Optuna\n",
    "\n",
    "### Ejercicio 2.1: Estudio Básico con Optuna\n",
    "\n",
    "**Objetivo:** Aprender la estructura básica de Optuna: Study, Trial y Objective.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Implementa una función objetivo para Optuna que entrene un modelo MLP para Fashion MNIST. La función debe:\n",
    "\n",
    "1. Sugerir los siguientes hiperparámetros:\n",
    "   - `n_layers`: número de capas (1 a 3)\n",
    "   - `n_units`: neuronas por capa (32 a 256)\n",
    "   - `dropout`: tasa de dropout (0.1 a 0.5)\n",
    "   - `learning_rate`: tasa de aprendizaje (1e-5 a 1e-2, escala log)\n",
    "   - `batch_size`: tamaño de batch (32, 64, o 128)\n",
    "\n",
    "2. Entrenar el modelo por 10 épocas\n",
    "\n",
    "3. Retornar la accuracy de validación\n",
    "\n",
    "**Pistas:**\n",
    "- `trial.suggest_int()` para enteros\n",
    "- `trial.suggest_float(..., log=True)` para escala logarítmica\n",
    "- `trial.suggest_categorical()` para elegir de una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# Cargar datos\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Separar validación\n",
    "x_val, y_val = x_train[:10000], y_train[:10000]\n",
    "x_train, y_train = x_train[10000:], y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    TODO: Implementa la función objetivo para Optuna.\n",
    "    \n",
    "    Debe:\n",
    "    1. Sugerir hiperparámetros usando trial.suggest_*\n",
    "    2. Construir y entrenar el modelo\n",
    "    3. Retornar la accuracy de validación\n",
    "    \"\"\"\n",
    "    # TODO: Sugerir hiperparámetros\n",
    "    # Tu código aquí\n",
    "    \n",
    "    # TODO: Construir modelo\n",
    "    # Tu código aquí\n",
    "    \n",
    "    # TODO: Entrenar y retornar accuracy\n",
    "    # Tu código aquí\n",
    "    \n",
    "    pass  # Eliminar esta línea cuando implementes la función\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y ejecutar el estudio\n",
    "# TODO: Crear estudio con optuna.create_study(direction='maximize')\n",
    "# TODO: Ejecutar study.optimize() con n_trials=15\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados y mejores hiperparámetros\n",
    "# TODO: Imprimir study.best_trial.value y study.best_trial.params\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Ejercicio 2.2: Pruning con Optuna\n",
    "\n",
    "**Objetivo:** Implementar poda (pruning) para detener entrenamientos no prometedores.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Modifica la función objetivo anterior para implementar pruning:\n",
    "\n",
    "1. Reportar la accuracy de validación después de cada época usando `trial.report()`\n",
    "2. Verificar si el trial debe ser podado usando `trial.should_prune()`\n",
    "3. Si debe ser podado, lanzar `optuna.TrialPruned()`\n",
    "\n",
    "Configura el estudio con un `MedianPruner` que:\n",
    "- Espere 3 trials antes de empezar a podar (`n_startup_trials=3`)\n",
    "- Espere 3 épocas antes de podar un trial (`n_warmup_steps=3`)\n",
    "\n",
    "**Pista:** Necesitarás crear un callback personalizado de Keras para reportar métricas a Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_with_pruning(trial):\n",
    "    \"\"\"\n",
    "    TODO: Implementa la función objetivo con pruning.\n",
    "    \n",
    "    Debe incluir:\n",
    "    1. Sugerencia de hiperparámetros\n",
    "    2. Un callback que reporte métricas y verifique pruning\n",
    "    3. Manejo de la excepción TrialPruned\n",
    "    \"\"\"\n",
    "    # TODO: Implementar con pruning\n",
    "    # Tu código aquí\n",
    "    \n",
    "    pass  # Eliminar esta línea cuando implementes la función\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear estudio con pruner y ejecutar\n",
    "# TODO: Crear estudio con MedianPruner\n",
    "# TODO: Ejecutar optimización\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar cuántos trials fueron podados\n",
    "# TODO: Contar trials completados vs podados\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Ejercicio 2.3: Visualizaciones de Optuna\n",
    "\n",
    "**Objetivo:** Utilizar las herramientas de visualización de Optuna para analizar resultados.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Usando el estudio del ejercicio anterior (o creando uno nuevo con al menos 20 trials), genera las siguientes visualizaciones:\n",
    "\n",
    "1. **Historia de optimización**: Muestra cómo evoluciona el mejor valor encontrado\n",
    "2. **Importancia de parámetros**: Identifica qué hiperparámetros tienen mayor impacto\n",
    "3. **Coordenadas paralelas**: Visualiza las relaciones entre hiperparámetros\n",
    "4. **Gráfico de contorno**: Para dos hiperparámetros seleccionados\n",
    "\n",
    "Después de generar las visualizaciones, responde:\n",
    "- ¿Cuál es el hiperparámetro más importante?\n",
    "- ¿Hay alguna correlación visible entre hiperparámetros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_parallel_coordinate,\n",
    "    plot_contour\n",
    ")\n",
    "\n",
    "# TODO: Generar las 4 visualizaciones\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuestas:**\n",
    "\n",
    "1. ¿Cuál es el hiperparámetro más importante?\n",
    "   - *Tu respuesta aquí*\n",
    "\n",
    "2. ¿Hay alguna correlación visible entre hiperparámetros?\n",
    "   - *Tu respuesta aquí*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 3: Ray Tune\n",
    "\n",
    "### Ejercicio 3.1: Configuración Básica de Ray Tune\n",
    "\n",
    "**Objetivo:** Aprender a configurar espacios de búsqueda y ejecutar experimentos con Ray Tune.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Configura un experimento de Ray Tune para optimizar un modelo de clasificación en CIFAR-10. Debes:\n",
    "\n",
    "1. Definir un espacio de búsqueda con:\n",
    "   - `conv_filters`: [32, 64, 128] (categorical)\n",
    "   - `dense_units`: 64 a 512 (uniforme)\n",
    "   - `learning_rate`: 1e-4 a 1e-1 (log-uniforme)\n",
    "   - `batch_size`: [32, 64, 128] (categorical)\n",
    "\n",
    "2. Crear una función de entrenamiento que:\n",
    "   - Construya una CNN simple (2-3 capas conv + dense)\n",
    "   - Reporte métricas a Ray Tune usando `tune.report()`\n",
    "\n",
    "3. Ejecutar la búsqueda con 10 trials\n",
    "\n",
    "**Nota:** CIFAR-10 tiene imágenes de 32x32x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "# Inicializar Ray\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
    "\n",
    "print(f\"Shape: {x_train.shape}\")\n",
    "print(f\"Clases: {np.unique(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Definir el espacio de búsqueda\n",
    "search_space = {\n",
    "    # Tu código aquí\n",
    "}\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar(config):\n",
    "    \"\"\"\n",
    "    TODO: Implementa la función de entrenamiento para Ray Tune.\n",
    "    \n",
    "    Debe:\n",
    "    1. Cargar los datos de CIFAR-10\n",
    "    2. Construir una CNN usando los hiperparámetros de config\n",
    "    3. Entrenar y reportar métricas con tune.report()\n",
    "    \"\"\"\n",
    "    # TODO: Implementar\n",
    "    # Tu código aquí\n",
    "    \n",
    "    pass  # Eliminar esta línea cuando implementes la función\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar la búsqueda\n",
    "# TODO: Usar tune.run() con la configuración apropiada\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar mejores resultados\n",
    "# TODO: Obtener y mostrar la mejor configuración\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Ejercicio 3.2: Scheduler ASHA\n",
    "\n",
    "**Objetivo:** Utilizar el scheduler ASHA para detención temprana eficiente.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Modifica el ejercicio anterior para usar el scheduler ASHA (Asynchronous Successive Halving Algorithm):\n",
    "\n",
    "1. Configura un `ASHAScheduler` con:\n",
    "   - `max_t=50` (máximo de épocas)\n",
    "   - `grace_period=10` (épocas mínimas antes de podar)\n",
    "   - `reduction_factor=3`\n",
    "\n",
    "2. Aumenta el número de trials a 20\n",
    "\n",
    "3. Compara el tiempo total de búsqueda con el ejercicio anterior\n",
    "\n",
    "**Pregunta:** ¿Cuántos trials fueron detenidos tempranamente? ¿Cuál fue el ahorro de tiempo aproximado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# TODO: Configurar ASHAScheduler\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ejecutar búsqueda con ASHA\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analizar resultados y trials detenidos\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuestas:**\n",
    "\n",
    "1. ¿Cuántos trials fueron detenidos tempranamente?\n",
    "   - *Tu respuesta aquí*\n",
    "\n",
    "2. ¿Cuál fue el ahorro de tiempo aproximado?\n",
    "   - *Tu respuesta aquí*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar Ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 4: TensorBoard HParams\n",
    "\n",
    "### Ejercicio 4.1: Registro de Experimentos\n",
    "\n",
    "**Objetivo:** Aprender a registrar hiperparámetros y métricas en TensorBoard.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Crea un experimento sistemático que pruebe las siguientes combinaciones de hiperparámetros:\n",
    "\n",
    "1. **Optimizadores**: Adam, SGD con momentum, RMSprop\n",
    "2. **Learning rates**: 0.001, 0.01, 0.1\n",
    "3. **Tamaños de batch**: 32, 128\n",
    "\n",
    "Para cada combinación:\n",
    "- Entrena un modelo MLP simple en MNIST por 5 épocas\n",
    "- Registra los hiperparámetros y la accuracy final en TensorBoard\n",
    "\n",
    "**Total de experimentos:** 3 × 3 × 2 = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Limpiar logs anteriores\n",
    "if os.path.exists(\"logs/ejercicio_4\"):\n",
    "    shutil.rmtree(\"logs/ejercicio_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Definir los hiperparámetros con hp.HParam\n",
    "# HP_OPTIMIZER = hp.HParam(...)\n",
    "# HP_LEARNING_RATE = hp.HParam(...)\n",
    "# HP_BATCH_SIZE = hp.HParam(...)\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Configurar el directorio de logs y hp.hparams_config\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(hparams, run_dir):\n",
    "    \"\"\"\n",
    "    TODO: Implementa la función que ejecuta un experimento.\n",
    "    \n",
    "    Debe:\n",
    "    1. Crear el modelo\n",
    "    2. Configurar el optimizador según hparams\n",
    "    3. Entrenar por 5 épocas\n",
    "    4. Retornar la accuracy en test\n",
    "    \"\"\"\n",
    "    # Tu código aquí\n",
    "    \n",
    "    pass  # Eliminar esta línea cuando implementes la función\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ejecutar todos los experimentos en un bucle\n",
    "# Registrar hiperparámetros y métricas con hp.hparams() y tf.summary.scalar()\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar TensorBoard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar en TensorBoard\n",
    "%tensorboard --logdir logs/ejercicio_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Ejercicio 4.2: Análisis de Resultados\n",
    "\n",
    "**Objetivo:** Analizar los resultados usando la interfaz de TensorBoard HParams.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Usando la visualización de TensorBoard del ejercicio anterior, responde las siguientes preguntas:\n",
    "\n",
    "1. ¿Cuál combinación de hiperparámetros dio la mejor accuracy?\n",
    "2. ¿Qué optimizador tuvo mejor rendimiento promedio?\n",
    "3. ¿El learning rate de 0.1 funcionó bien con todos los optimizadores?\n",
    "4. ¿Hubo diferencia significativa entre batch size 32 y 128?\n",
    "\n",
    "**Instrucciones:**\n",
    "- En TensorBoard, ve a la pestaña \"HPARAMS\"\n",
    "- Usa la tabla para ordenar por accuracy\n",
    "- Usa el gráfico de coordenadas paralelas para ver patrones\n",
    "- Filtra por diferentes valores para responder las preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuestas:**\n",
    "\n",
    "1. ¿Cuál combinación de hiperparámetros dio la mejor accuracy?\n",
    "   - *Tu respuesta aquí*\n",
    "\n",
    "2. ¿Qué optimizador tuvo mejor rendimiento promedio?\n",
    "   - *Tu respuesta aquí*\n",
    "\n",
    "3. ¿El learning rate de 0.1 funcionó bien con todos los optimizadores?\n",
    "   - *Tu respuesta aquí*\n",
    "\n",
    "4. ¿Hubo diferencia significativa entre batch size 32 y 128?\n",
    "   - *Tu respuesta aquí*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parte 5: Ejercicios Integradores\n",
    "\n",
    "### Ejercicio 5.1: Comparación de Herramientas\n",
    "\n",
    "**Objetivo:** Comparar las diferentes herramientas en un mismo problema.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Realiza una búsqueda de hiperparámetros para el mismo modelo y dataset usando tres herramientas diferentes:\n",
    "\n",
    "1. **Keras Tuner** con BayesianOptimization\n",
    "2. **Optuna** con MedianPruner\n",
    "3. **Ray Tune** con ASHAScheduler\n",
    "\n",
    "**Configuración común:**\n",
    "- Dataset: Fashion MNIST\n",
    "- Modelo: MLP con 1-3 capas ocultas\n",
    "- Hiperparámetros: número de capas, neuronas por capa, dropout, learning rate\n",
    "- Número de trials: 15 por herramienta\n",
    "- Épocas máximas: 20\n",
    "\n",
    "**Métricas a comparar:**\n",
    "- Mejor accuracy encontrada\n",
    "- Tiempo total de búsqueda\n",
    "- Facilidad de uso (subjetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos comunes para todos los experimentos\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_val, y_val = x_train[:10000], y_train[:10000]\n",
    "x_train, y_train = x_train[10000:], y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "results = {\n",
    "    'keras_tuner': {'best_accuracy': None, 'time': None},\n",
    "    'optuna': {'best_accuracy': None, 'time': None},\n",
    "    'ray_tune': {'best_accuracy': None, 'time': None}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar búsqueda con Keras Tuner\n",
    "print(\"=\" * 50)\n",
    "print(\"KERAS TUNER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Tu código aquí\n",
    "\n",
    "results['keras_tuner']['time'] = time.time() - start_time\n",
    "# results['keras_tuner']['best_accuracy'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar búsqueda con Optuna\n",
    "print(\"=\" * 50)\n",
    "print(\"OPTUNA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Tu código aquí\n",
    "\n",
    "results['optuna']['time'] = time.time() - start_time\n",
    "# results['optuna']['best_accuracy'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar búsqueda con Ray Tune\n",
    "print(\"=\" * 50)\n",
    "print(\"RAY TUNE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "start_time = time.time()\n",
    "\n",
    "# Tu código aquí\n",
    "\n",
    "results['ray_tune']['time'] = time.time() - start_time\n",
    "# results['ray_tune']['best_accuracy'] = ...\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar comparación\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"COMPARACIÓN DE RESULTADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for tool, data in results.items():\n",
    "    print(f\"\\n{tool.upper()}:\")\n",
    "    print(f\"  Mejor accuracy: {data['best_accuracy']:.4f}\")\n",
    "    print(f\"  Tiempo total: {data['time']:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Ejercicio 5.2: Optimización de CNN para CIFAR-10\n",
    "\n",
    "**Objetivo:** Aplicar todo lo aprendido en un problema más complejo.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Diseña y ejecuta una búsqueda completa de hiperparámetros para una CNN en CIFAR-10 usando la herramienta de tu preferencia. El objetivo es alcanzar al menos **70% de accuracy** en el conjunto de test.\n",
    "\n",
    "**Requisitos:**\n",
    "\n",
    "1. La arquitectura debe incluir:\n",
    "   - Al menos 2 bloques convolucionales\n",
    "   - Capas de pooling\n",
    "   - Al menos una capa densa\n",
    "   - Regularización (dropout y/o batch normalization)\n",
    "\n",
    "2. Hiperparámetros a buscar (mínimo 5):\n",
    "   - Número de filtros\n",
    "   - Tamaño de kernel\n",
    "   - Tipo de pooling (Max vs Average)\n",
    "   - Dropout rate\n",
    "   - Learning rate\n",
    "   - Optimizador\n",
    "   - Número de capas densas\n",
    "   - Uso de batch normalization\n",
    "\n",
    "3. Utiliza detención temprana o pruning para eficiencia\n",
    "\n",
    "4. Documenta tu proceso y justifica tus decisiones\n",
    "\n",
    "**Entregables:**\n",
    "- Código completo de la búsqueda\n",
    "- Mejores hiperparámetros encontrados\n",
    "- Accuracy final en test\n",
    "- Análisis de qué hiperparámetros fueron más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
    "\n",
    "# Separar validación\n",
    "x_val, y_val = x_train[:5000], y_train[:5000]\n",
    "x_train, y_train = x_train[5000:], y_train[5000:]\n",
    "\n",
    "print(f\"Entrenamiento: {x_train.shape}\")\n",
    "print(f\"Validación: {x_val.shape}\")\n",
    "print(f\"Test: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar tu solución aquí\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Entrenar modelo final con mejores hiperparámetros\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluar en test y mostrar resultados\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis y conclusiones:**\n",
    "\n",
    "1. ¿Qué herramienta elegiste y por qué?\n",
    "   - *Tu respuesta aquí*\n",
    "\n",
    "2. ¿Cuáles fueron los mejores hiperparámetros encontrados?\n",
    "   - *Tu respuesta aquí*\n",
    "\n",
    "3. ¿Qué hiperparámetros tuvieron mayor impacto en el rendimiento?\n",
    "   - *Tu respuesta aquí*\n",
    "\n",
    "4. ¿Alcanzaste el objetivo del 70%? Si no, ¿qué más intentarías?\n",
    "   - *Tu respuesta aquí*\n",
    "\n",
    "5. ¿Cuánto tiempo tomó la búsqueda y cuántos trials se ejecutaron?\n",
    "   - *Tu respuesta aquí*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Ejercicio Bonus: Transfer Learning con Optimización\n",
    "\n",
    "**Objetivo:** Combinar transfer learning con búsqueda de hiperparámetros.\n",
    "\n",
    "**Enunciado:**\n",
    "\n",
    "Utiliza un modelo preentrenado (MobileNetV2) como base y optimiza los hiperparámetros de las capas que agregues encima. \n",
    "\n",
    "**Hiperparámetros a buscar:**\n",
    "- Número de capas densas adicionales (1-3)\n",
    "- Neuronas en cada capa\n",
    "- Si descongelar las últimas N capas del modelo base\n",
    "- Learning rate para fine-tuning\n",
    "\n",
    "**Dataset:** CIFAR-10 redimensionado a 96x96 para MobileNetV2\n",
    "\n",
    "**Nota:** Este ejercicio requiere más recursos computacionales. Considera usar Google Colab con GPU si tu máquina local es lenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implementar transfer learning con búsqueda de hiperparámetros\n",
    "# Este es un ejercicio avanzado opcional\n",
    "\n",
    "# Tu código aquí\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resumen y Reflexión Final\n",
    "\n",
    "Después de completar estos ejercicios, reflexiona sobre las siguientes preguntas:\n",
    "\n",
    "1. ¿Cuál herramienta te resultó más intuitiva de usar?\n",
    "\n",
    "2. ¿En qué situaciones usarías cada herramienta?\n",
    "\n",
    "3. ¿Qué aprendiste sobre la importancia relativa de los diferentes hiperparámetros?\n",
    "\n",
    "4. ¿Cómo cambiaría tu enfoque si tuvieras acceso a múltiples GPUs?\n",
    "\n",
    "5. ¿Qué estrategias usarías para reducir el tiempo de búsqueda en proyectos reales?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}