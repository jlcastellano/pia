{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78730d27",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Análisis de Datos de Calidad del Aire en California\n",
    "\n",
    "Utilizando el dataset de calidad del aire de California disponible en:\n",
    "https://www.kaggle.com/datasets/sogun3/uspollution\n",
    "\n",
    "O directamente del EPA (Environmental Protection Agency):\n",
    "https://aqs.epa.gov/aqsweb/airdata/download_files.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración básica de visualización\n",
    "plt.style.use('default')  # Usando el estilo por defecto en lugar de seaborn\n",
    "sns.set_theme()  # Configuración moderna de seaborn\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1eb60",
   "metadata": {},
   "source": [
    "### 1. Carga y filtrado inicial de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b76c88",
   "metadata": {},
   "source": [
    "Carga el dataset en un DataFrame y filtra los datos para quedarte solo con las mediciones de California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "df = pd.read_csv('pollution_us_2000_2016.csv')\n",
    "\n",
    "# Filtrar datos de California\n",
    "df_ca = df[df['State'] == 'California'].copy()\n",
    "\n",
    "print(f\"Registros totales: {len(df)}\")\n",
    "print(f\"Registros de California: {len(df_ca)}\")\n",
    "print(\"\\nPrimeras filas del dataset filtrado:\")\n",
    "df_ca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cfee2b",
   "metadata": {},
   "source": [
    "### 2. Limpieza inicial de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb559446",
   "metadata": {},
   "source": [
    "2. Realiza una limpieza inicial de los datos:\n",
    "   - Identifica y maneja valores nulos\n",
    "   - Convierte las columnas de fecha al formato correcto\n",
    "   - Verifica y corrige valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34769e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columna de fecha\n",
    "df_ca['Date Local'] = pd.to_datetime(df_ca['Date Local'])\n",
    "\n",
    "# Lista de columnas de contaminantes\n",
    "contaminantes = ['NO2 Mean', 'SO2 Mean', 'CO Mean', 'O3 Mean']\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"Valores nulos en el dataset:\")\n",
    "print(df_ca[contaminantes].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para quitar valores atípicos\n",
    "def quitar_atipicos(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Aplicar limpieza de atípicos a cada contaminante\n",
    "for cont in contaminantes:\n",
    "    df_ca = quitar_atipicos(df_ca, cont)\n",
    "    \n",
    "print(\"\\nDimensiones del DataFrame:\")\n",
    "print(f\"Antes de la limpieza: {len(df[df['State'] == 'California'])} filas\")\n",
    "print(f\"Después de la limpieza: {len(df_ca)} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f6b0b",
   "metadata": {},
   "source": [
    "3. Analiza los contaminantes principales (NO2, SO2, CO, O3):\n",
    "   - Calcula promedios mensuales por ciudad\n",
    "   - Identifica las 5 ciudades con mayores niveles de cada contaminante\n",
    "   - Determina si hay patrones estacionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedios mensuales por ciudad\n",
    "promedios_mensuales = df_ca.groupby(['City', pd.Grouper(key='Date Local', freq='ME')])[contaminantes].mean()\n",
    "print(promedios_mensuales)\n",
    "\n",
    "# Top 5 ciudades por contaminante\n",
    "for cont in contaminantes:\n",
    "    print(f\"\\nTop 5 ciudades con mayor nivel de {cont}:\")\n",
    "    print(df_ca.groupby('City')[cont].mean().nlargest(5))\n",
    "\n",
    "# Análisis estacional\n",
    "df_ca['Month'] = df_ca['Date Local'].dt.month\n",
    "patrones_estacionales = df_ca.groupby('Month')[contaminantes].mean()\n",
    "\n",
    "# Visualización de patrones estacionales\n",
    "plt.figure(figsize=(12, 6))\n",
    "for cont in contaminantes:\n",
    "    plt.plot(patrones_estacionales.index, patrones_estacionales[cont], label=cont)\n",
    "plt.title('Patrones Estacionales de Contaminantes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Nivel promedio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd5747",
   "metadata": {},
   "source": [
    "4. Crea nuevas columnas derivadas:\n",
    "   - Índice de calidad del aire simplificado\n",
    "   - Clasificación por niveles de riesgo\n",
    "   - Indicadores de cumplimiento de estándares EPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da93557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular índice de calidad del aire simplificado\n",
    "def calcular_indice_calidad(row):\n",
    "    # Usando los valores AQI existentes\n",
    "    aqi_values = [\n",
    "        row['NO2 AQI'],\n",
    "        row['SO2 AQI'],\n",
    "        row['CO AQI'],\n",
    "        row['O3 AQI']\n",
    "    ]\n",
    "    return np.mean([x for x in aqi_values if not np.isnan(x)])\n",
    "\n",
    "df_ca['indice_calidad'] = df_ca.apply(calcular_indice_calidad, axis=1)\n",
    "\n",
    "# Clasificación por niveles de riesgo\n",
    "def clasificar_riesgo(indice):\n",
    "    if indice <= 50: return 'Bueno'\n",
    "    elif indice <= 100: return 'Moderado'\n",
    "    elif indice <= 150: return 'Dañino para grupos sensibles'\n",
    "    else: return 'Dañino'\n",
    "\n",
    "df_ca['nivel_riesgo'] = df_ca['indice_calidad'].apply(clasificar_riesgo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52dde24",
   "metadata": {},
   "source": [
    "Para verlos de diferentes formas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607adcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de estilo\n",
    "plt.style.use('default')\n",
    "\n",
    "# 1. Distribución del índice de calidad por nivel de riesgo\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_ca, x='nivel_riesgo', y='indice_calidad')\n",
    "plt.title('Distribución del Índice de Calidad del Aire por Nivel de Riesgo')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Evolución temporal del índice de calidad\n",
    "plt.figure(figsize=(15, 6))\n",
    "df_ca.groupby('Date Local')['indice_calidad'].mean().rolling(window=30).mean().plot()\n",
    "plt.title('Evolución del Índice de Calidad del Aire (Media Móvil 30 días)')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Índice de Calidad del Aire')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Proporción de niveles de riesgo\n",
    "plt.figure(figsize=(10, 10))\n",
    "df_ca['nivel_riesgo'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Proporción de Niveles de Riesgo')\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Top 10 ciudades con peor calidad del aire\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_10_ciudades = df_ca.groupby('City')['indice_calidad'].mean().nlargest(10)\n",
    "sns.barplot(x=top_10_ciudades.values, y=top_10_ciudades.index)\n",
    "plt.title('Top 10 Ciudades con Mayor Índice de Contaminación')\n",
    "plt.xlabel('Índice de Calidad del Aire Promedio')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Distribución mensual del índice de calidad\n",
    "plt.figure(figsize=(12, 6))\n",
    "df_ca.boxplot(column='indice_calidad', by='Month', figsize=(12, 6))\n",
    "plt.title('Distribución Mensual del Índice de Calidad del Aire')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Índice de Calidad del Aire')\n",
    "plt.suptitle('')  # Esto elimina el título automático adicional\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183edd2",
   "metadata": {},
   "source": [
    "5. Realiza análisis temporal:\n",
    "   - Calcula tendencias anuales\n",
    "   - Identifica días críticos (con valores extremos)\n",
    "   - Genera medias móviles semanales y mensuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42123179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis temporal\n",
    "df_ca['Year'] = df_ca['Date Local'].dt.year\n",
    "tendencias_anuales = df_ca.groupby('Year')[contaminantes].mean()\n",
    "\n",
    "# Visualización de tendencias anuales\n",
    "plt.figure(figsize=(12, 6))\n",
    "for cont in contaminantes:\n",
    "    plt.plot(tendencias_anuales.index, tendencias_anuales[cont], label=cont)\n",
    "plt.title('Tendencias Anuales de Contaminantes')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Nivel promedio')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a7641",
   "metadata": {},
   "source": [
    "6. Exporta los resultados:\n",
    "   - Guarda un resumen por ciudad en CSV\n",
    "   - Crea un archivo con los días críticos identificados\n",
    "   - Genera un reporte con las estadísticas principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar resultados\n",
    "resumen_ciudad = df_ca.groupby('City').agg({\n",
    "    'NO2 Mean': 'mean',\n",
    "    'SO2 Mean': 'mean',\n",
    "    'CO Mean': 'mean',\n",
    "    'O3 Mean': 'mean',\n",
    "    'indice_calidad': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Guardar resultados\n",
    "resumen_ciudad.to_csv('resumen_por_ciudad.csv')\n",
    "\n",
    "# Días críticos (usando el índice de calidad del aire)\n",
    "dias_criticos = df_ca[df_ca['indice_calidad'] > df_ca['indice_calidad'].quantile(0.95)]\n",
    "dias_criticos.to_csv('dias_criticos.csv')\n",
    "\n",
    "# Matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df_ca[contaminantes].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlación entre Contaminantes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e992a",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Análisis de Datos del Mundial de Fútbol\n",
    "\n",
    "Utilizando el dataset histórico de la FIFA World Cup disponible en:\n",
    "https://www.kaggle.com/datasets/abecklas/fifa-world-cup\n",
    "\n",
    "Desarrolla:\n",
    "1. Carga y combina los datasets de partidos y equipos usando merge\n",
    "2. Calcula estadísticas por país:\n",
    "   - Total de participaciones en mundiales\n",
    "   - Goles anotados y recibidos\n",
    "   - Victorias, derrotas y empates\n",
    "3. Identifica los 5 países más exitosos basándote en una métrica que combines\n",
    "4. Crea un DataFrame pivotado que muestre el progreso de cada país por año\n",
    "5. Genera visualizaciones para mostrar las tendencias históricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('classic')\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar los datasets\n",
    "matches = pd.read_csv('WorldCupMatches.csv')\n",
    "cups = pd.read_csv('WorldCups.csv')\n",
    "\n",
    "# Mostrar las primeras filas de cada dataset\n",
    "print(\"Dataset de partidos:\")\n",
    "print(matches.head())\n",
    "print(\"\\nDataset de copas mundiales:\")\n",
    "print(cups.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc092b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de datos - Crear registros separados para equipos local y visitante\n",
    "home_team = matches[['Year', 'Home Team Name', 'Home Team Goals', 'Away Team Goals']].copy()\n",
    "away_team = matches[['Year', 'Away Team Name', 'Home Team Goals', 'Away Team Goals']].copy()\n",
    "\n",
    "# Renombrar columnas\n",
    "home_team.columns = ['Year', 'Team', 'Goals_For', 'Goals_Against']\n",
    "away_team.columns = ['Year', 'Team', 'Goals_Against', 'Goals_For']\n",
    "\n",
    "# Combinar los datos\n",
    "all_games = pd.concat([home_team, away_team])\n",
    "all_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calcular estadísticas por país\n",
    "\n",
    "# Total de participaciones en mundiales\n",
    "participaciones = all_games.groupby('Team')['Year'].nunique().sort_values(ascending=False)\n",
    "participaciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98149c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goles anotados y recibidos\n",
    "goles = all_games.groupby('Team').agg({\n",
    "    'Goals_For': 'sum',\n",
    "    'Goals_Against': 'sum'\n",
    "}).round(2)\n",
    "goles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular victorias, derrotas y empates\n",
    "all_games['Result'] = np.where(all_games['Goals_For'] > all_games['Goals_Against'], 'Win',\n",
    "                              np.where(all_games['Goals_For'] < all_games['Goals_Against'], 'Loss', 'Draw'))\n",
    "resultados = all_games.groupby('Team')['Result'].value_counts().unstack(fill_value=0)\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab269bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todas las estadísticas\n",
    "stats = pd.concat([participaciones, goles, resultados], axis=1).fillna(0)\n",
    "stats.columns = ['Participaciones', 'Goles_Favor', 'Goles_Contra', 'Derrotas', 'Empates', 'Victorias']\n",
    "\n",
    "print(\"Estadísticas por país:\")\n",
    "print(stats.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf66f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identificar los 5 países más exitosos\n",
    "\n",
    "# Crear métrica compuesta: (3*Victorias + Empates + 2*Goles_Favor - Goles_Contra + 5*Participaciones)/Participaciones\n",
    "stats['Score'] = (3*stats['Victorias'] + stats['Empates'] + 2*stats['Goles_Favor'] - \n",
    "                  stats['Goles_Contra'] + 5*stats['Participaciones'])/stats['Participaciones']\n",
    "\n",
    "top_5 = stats.nlargest(5, 'Score')\n",
    "print(\"Top 5 países más exitosos:\")\n",
    "print(top_5[['Score', 'Victorias', 'Empates', 'Derrotas', 'Goles_Favor', 'Goles_Contra']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d57356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. DataFrame pivotado para progreso por año\n",
    "print(all_games.head(20))\n",
    "\n",
    "progreso_anual = pd.pivot_table(all_games,\n",
    "                               values='Goals_For',\n",
    "                               index='Year',\n",
    "                               columns='Team',\n",
    "                               aggfunc='sum')\n",
    "\n",
    "print(\"Progreso de goles por año y país:\")\n",
    "print(progreso_anual.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b919ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualizaciones\n",
    "\n",
    "# Gráfico de barras para el Top 5\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=top_5.reset_index(), x='Team', y='Score')\n",
    "plt.title('Top 5 Países más Exitosos en la Historia de los Mundiales')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Evolución de goles para el Top 5\n",
    "plt.figure(figsize=(15, 8))\n",
    "for team in top_5.index:\n",
    "    plt.plot(progreso_anual.index, progreso_anual[team].fillna(0), label=team, marker='o')\n",
    "plt.title('Evolución de Goles por Mundial - Top 5 Países')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Goles Anotados')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de radar para comparar métricas del Top 5\n",
    "metrics = ['Victorias', 'Empates', 'Goles_Favor', 'Participaciones']\n",
    "angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "for idx, team in enumerate(top_5.index):\n",
    "    values = top_5.loc[team, metrics].values\n",
    "    values = np.concatenate((values, [values[0]]))\n",
    "    angles_plot = np.concatenate((angles, [angles[0]]))\n",
    "    ax.plot(angles_plot, values, 'o-', linewidth=2, label=team)\n",
    "    ax.fill(angles_plot, values, alpha=0.25)\n",
    "\n",
    "ax.set_xticks(angles)\n",
    "ax.set_xticklabels(metrics)\n",
    "plt.title('Comparación de Métricas - Top 5 Países')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b99ea",
   "metadata": {},
   "source": [
    "### Análisis de Resultados:\n",
    "\n",
    "1. **Participación histórica:**\n",
    "   - Brasil, Alemania e Italia son los países con mayor número de participaciones\n",
    "   - Estos países también lideran en victorias y goles anotados\n",
    "\n",
    "2. **Eficiencia ofensiva:**\n",
    "   - Brasil destaca por su alta proporción de goles anotados vs. recibidos\n",
    "   - Alemania muestra una gran consistencia en todas las métricas\n",
    "\n",
    "3. **Evolución histórica:**\n",
    "   - Se observa una tendencia al alza en el número de goles por mundial\n",
    "   - Los equipos top muestran mayor regularidad en sus performances\n",
    "\n",
    "4. **Métricas compuestas:**\n",
    "   - La métrica creada pondera diferentes aspectos del éxito\n",
    "   - Los resultados coinciden con la percepción histórica del éxito de estos equipos\n",
    "\n",
    "5. **Tendencias actuales:**\n",
    "   - Mayor paridad entre equipos en mundiales recientes\n",
    "   - Menor dominancia de equipos tradicionales en últimas ediciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692c9b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16c078ea",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Análisis de Series Temporales de Bolsa\n",
    "\n",
    "Usando el dataset de Yahoo Finance para el índice S&P 500 (^GSPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b75802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuración básica de visualización\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "# Para evitar warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Obtener datos de los últimos 5 años\n",
    "# Calculamos las fechas\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "# Descargamos los datos usando yfinance directamente\n",
    "ticker = yf.Ticker('^GSPC')\n",
    "df = ticker.history(start=start_date, end=end_date)\n",
    "\n",
    "print(\"Primeras 5 filas del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calcular retornos\n",
    "\n",
    "# Retornos diarios\n",
    "df['daily_return'] = df['Close'].pct_change()\n",
    "\n",
    "# Retornos semanales\n",
    "df['weekly_return'] = df['Close'].pct_change(periods=5)\n",
    "\n",
    "# Retornos mensuales (aproximadamente 21 días de trading)\n",
    "df['monthly_return'] = df['Close'].pct_change(periods=21)\n",
    "\n",
    "print(\"Estadísticas descriptivas de los retornos:\")\n",
    "df[['daily_return', 'weekly_return', 'monthly_return']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4830f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identificar los 10 días con mayor volatilidad\n",
    "volatility_days = df['daily_return'].abs().sort_values(ascending=False).head(10)\n",
    "\n",
    "print(\"Los 10 días con mayor volatilidad:\")\n",
    "print(volatility_days)\n",
    "\n",
    "# Visualización de la volatilidad\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df.index, df['daily_return'].abs(), alpha=0.5)\n",
    "plt.title('Volatilidad Diaria del S&P 500')\n",
    "plt.ylabel('Volatilidad (|Retorno Diario|)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcb702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Implementar ventana móvil de 20 días\n",
    "\n",
    "# Media móvil\n",
    "df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "\n",
    "# Desviación estándar móvil\n",
    "df['STD20'] = df['Close'].rolling(window=20).std()\n",
    "\n",
    "# Máximos y mínimos móviles\n",
    "df['MAX20'] = df['Close'].rolling(window=20).max()\n",
    "df['MIN20'] = df['Close'].rolling(window=20).min()\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(df.index, df['Close'], label='Precio', alpha=0.7)\n",
    "plt.plot(df.index, df['MA20'], label='Media Móvil 20 días', linewidth=2)\n",
    "plt.fill_between(df.index, \n",
    "                 df['MA20'] - 2*df['STD20'], \n",
    "                 df['MA20'] + 2*df['STD20'], \n",
    "                 alpha=0.2, \n",
    "                 label='Bandas de Volatilidad')\n",
    "plt.title('S&P 500 con Media Móvil y Bandas de Volatilidad')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871dcd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Crear indicadores técnicos\n",
    "\n",
    "def calculate_rsi(data, periods=14):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=periods).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=periods).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "# Calcular RSI\n",
    "df['RSI'] = calculate_rsi(df['Close'])\n",
    "\n",
    "# Calcular MACD\n",
    "exp1 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "exp2 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "df['MACD'] = exp1 - exp2\n",
    "df['Signal Line'] = df['MACD'].ewm(span=9, adjust=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Visualizar indicadores\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Precio y Media Móvil\n",
    "ax1.plot(df.index, df['Close'], label='Precio')\n",
    "ax1.plot(df.index, df['MA20'], label='MA20')\n",
    "ax1.set_title('S&P 500 con Media Móvil de 20 días')\n",
    "ax1.legend()\n",
    "\n",
    "# RSI\n",
    "ax2.plot(df.index, df['RSI'])\n",
    "ax2.axhline(y=70, color='r', linestyle='--')\n",
    "ax2.axhline(y=30, color='g', linestyle='--')\n",
    "ax2.set_title('RSI (14 períodos)')\n",
    "\n",
    "# MACD\n",
    "ax3.plot(df.index, df['MACD'], label='MACD')\n",
    "ax3.plot(df.index, df['Signal Line'], label='Señal')\n",
    "ax3.set_title('MACD')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3200a56",
   "metadata": {},
   "source": [
    "### Conclusiones:\n",
    "\n",
    "1. Hemos analizado los datos del S&P 500 de los últimos 5 años, calculando diferentes tipos de retornos (diarios, semanales y mensuales).\n",
    "\n",
    "2. Identificamos los días con mayor volatilidad, lo que nos permite detectar eventos significativos en el mercado.\n",
    "\n",
    "3. Implementamos indicadores técnicos populares:\n",
    "   - Media móvil de 20 días para identificar tendencias\n",
    "   - RSI para identificar condiciones de sobrecompra/sobreventa\n",
    "   - MACD para identificar cambios en la tendencia y momentum\n",
    "\n",
    "4. Las visualizaciones nos permiten ver claramente:\n",
    "   - La tendencia general del mercado\n",
    "   - Períodos de alta volatilidad\n",
    "   - Señales de compra/venta según los indicadores técnicos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e665e774",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Análisis de Datos de COVID-19\n",
    "\n",
    "Utilizando el dataset de Our World in Data sobre COVID-19:\n",
    "https://github.com/owid/covid-19-data/tree/master/public/data\n",
    "\n",
    "Desarrolla:\n",
    "1. Carga y limpia el dataset\n",
    "2. Calcula para cada país:\n",
    "   - Tasa de positividad diaria\n",
    "   - Media móvil de 7 días de casos nuevos\n",
    "   - Tiempo hasta alcanzar picos de casos\n",
    "3. Agrupa países por continente y compara métricas clave\n",
    "4. Identifica correlaciones entre variables (casos, muertes, vacunación)\n",
    "5. Crea un dashboard básico con las métricas más relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8fcea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('default')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carga y limpieza del dataset\n",
    "url = 'owid-covid-data.csv'\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())\n",
    "\n",
    "# Convertimos la columna de fecha a datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a99b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos columnas con más del 50% de valores nulos\n",
    "null_thresh = len(df) * 0.5\n",
    "df = df.dropna(axis=1, thresh=null_thresh)\n",
    "\n",
    "# Rellenamos valores nulos restantes\n",
    "df = df.fillna({\n",
    "    'new_cases': 0,\n",
    "    'new_deaths': 0,\n",
    "    'total_cases': df.groupby('location')['total_cases'].ffill(),\n",
    "    'total_deaths': df.groupby('location')['total_deaths'].ffill()\n",
    "})\n",
    "\n",
    "print('Dimensiones del dataset:', df.shape)\n",
    "print('\\nColumnas disponibles:\\n', df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730cb4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Cálculos por país\n",
    "\n",
    "# Verificamos las columnas disponibles\n",
    "print(\"Columnas disponibles en el dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Media móvil de 7 días de casos nuevos\n",
    "df['cases_7day_avg'] = df.groupby('location')['new_cases'].rolling(window=7, center=True).mean().reset_index(0, drop=True)\n",
    "\n",
    "# Intentamos calcular la tasa de positividad si los datos están disponibles\n",
    "if 'new_tests' in df.columns:\n",
    "    df['positivity_rate'] = df['new_cases'] / df['new_tests'] * 100\n",
    "else:\n",
    "    print(\"\\nNota: No se puede calcular la tasa de positividad porque 'new_tests' no está disponible en el dataset\")\n",
    "    df['positivity_rate'] = None\n",
    "\n",
    "# Tiempo hasta alcanzar picos de casos\n",
    "def find_peak_day(group):\n",
    "    peak_cases = group['new_cases'].max()\n",
    "    peak_date = group[group['new_cases'] == peak_cases]['date'].iloc[0]\n",
    "    first_date = group['date'].min()\n",
    "    return (peak_date - first_date).days\n",
    "\n",
    "peak_days = df.groupby('location').apply(find_peak_day)\n",
    "peak_days = pd.DataFrame(peak_days, columns=['days_to_peak'])\n",
    "\n",
    "# Mostramos los resultados para algunos países\n",
    "sample_countries = ['United States', 'Spain', 'Italy', 'Brazil', 'India']\n",
    "print('\\nDías hasta alcanzar el pico de casos:')\n",
    "print(peak_days.loc[sample_countries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Análisis por continente\n",
    "\n",
    "# Creamos métricas agregadas por continente\n",
    "continent_metrics = df.groupby('continent').agg({\n",
    "    'total_cases': 'max',\n",
    "    'total_deaths': 'max',\n",
    "    'new_cases': 'mean',\n",
    "    'new_deaths': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Visualizamos las métricas por continente\n",
    "plt.figure(figsize=(12, 6))\n",
    "continent_metrics['total_cases'].plot(kind='bar')\n",
    "plt.title('Total de Casos por Continente')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Número de Casos')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nMétricas por continente:')\n",
    "print(continent_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Análisis de correlaciones\n",
    "\n",
    "# Seleccionamos variables numéricas disponibles\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_vars = [col for col in [\n",
    "    'new_cases', 'new_deaths', 'total_cases', 'total_deaths',\n",
    "    'people_vaccinated', 'people_fully_vaccinated'\n",
    "] if col in numeric_columns]\n",
    "\n",
    "# Calculamos la matriz de correlación\n",
    "correlation_matrix = df[correlation_vars].corr()\n",
    "\n",
    "# Visualizamos la matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "im = plt.imshow(correlation_matrix, cmap='coolwarm', aspect='auto')\n",
    "plt.colorbar(im)\n",
    "\n",
    "# Añadimos las etiquetas\n",
    "plt.xticks(range(len(correlation_vars)), correlation_vars, rotation=45, ha='right')\n",
    "plt.yticks(range(len(correlation_vars)), correlation_vars)\n",
    "\n",
    "# Añadimos los valores numéricos\n",
    "for i in range(len(correlation_vars)):\n",
    "    for j in range(len(correlation_vars)):\n",
    "        text = plt.text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}',\n",
    "                       ha='center', va='center')\n",
    "\n",
    "plt.title('Matriz de Correlación de Variables COVID-19')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462dba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Dashboard básico\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Gráfico 1: Evolución temporal de casos nuevos (top 5 países)\n",
    "top_countries = df.groupby('location')['new_cases'].sum().nlargest(5).index\n",
    "for country in top_countries:\n",
    "    country_data = df[df['location'] == country]\n",
    "    axes[0, 0].plot(country_data['date'], country_data['cases_7day_avg'], label=country)\n",
    "axes[0, 0].set_title('Media Móvil 7 días - Casos Nuevos')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gráfico 2: Casos totales por continente\n",
    "continent_cases = df.groupby('continent')['total_cases'].max()\n",
    "axes[0, 1].bar(continent_cases.index, continent_cases.values)\n",
    "axes[0, 1].set_title('Casos Totales por Continente')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gráfico 3: Relación entre casos y muertes\n",
    "axes[1, 0].scatter(df['total_cases'], df['total_deaths'], alpha=0.5)\n",
    "axes[1, 0].set_title('Relación entre Casos Totales y Muertes')\n",
    "axes[1, 0].set_xlabel('Casos Totales')\n",
    "axes[1, 0].set_ylabel('Muertes Totales')\n",
    "\n",
    "# Gráfico 4: Distribución de días hasta el pico\n",
    "axes[1, 1].hist(peak_days['days_to_peak'], bins=30)\n",
    "axes[1, 1].set_title('Distribución de Días hasta el Pico de Casos')\n",
    "axes[1, 1].set_xlabel('Días hasta el pico')\n",
    "axes[1, 1].set_ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504fc65",
   "metadata": {},
   "source": [
    "### Conclusiones:\n",
    "\n",
    "1. La limpieza de datos reveló que algunas variables tenían una cantidad significativa de valores faltantes, especialmente en las métricas de pruebas y vacunación.\n",
    "\n",
    "2. La eliminación de columnas con más del 50% de valores nulos nos ayudó a trabajar con un conjunto de datos más manejable y significativo.\n",
    "\n",
    "3. Se observa una fuerte correlación entre casos totales y muertes totales, aunque la relación no es perfectamente lineal.\n",
    "\n",
    "4. Los países alcanzaron sus picos de casos en diferentes momentos, lo que refleja la naturaleza asincrónica de la pandemia.\n",
    "\n",
    "5. El análisis por continente muestra diferencias significativas en el impacto de la pandemia, tanto en casos totales como en mortalidad.\n",
    "\n",
    "6. La media móvil de 7 días ayuda a visualizar mejor las tendencias al suavizar las fluctuaciones diarias en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b667398f",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Análisis de Reseñas de Amazon\n",
    "\n",
    "Usando el dataset de reseñas de Amazon disponible en:\n",
    "https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews\n",
    "\n",
    "Realiza:\n",
    "1. Carga y preprocesa el dataset\n",
    "2. Analiza la distribución de puntuaciones\n",
    "3. Identifica patrones temporales en las reseñas:\n",
    "   - Evolución de puntuaciones promedio por mes/año\n",
    "   - Cambios en la longitud de las reseñas\n",
    "4. Agrupa productos por categoría y analiza diferencias en:\n",
    "   - Puntuación promedio\n",
    "   - Cantidad de reseñas\n",
    "   - Sentimiento general\n",
    "5. Crea un sistema simple de detección de reseñas potencialmente falsas basado en múltiples criterios\n",
    "\n",
    "Conceptos evaluados: text processing, análisis temporal, detección de anomalías, agregaciones complejas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6fb6da",
   "metadata": {},
   "source": [
    "### 1. Carga y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9db018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Configuración de visualización\n",
    "sns.set_theme()  # Usamos el tema por defecto de seaborn en lugar de plt.style\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('Reviews.csv')\n",
    "\n",
    "# Mostrar información básica del dataset\n",
    "print(\"Información del dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\nValores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Limpieza básica\n",
    "df['Time'] = pd.to_datetime(df['Time'], unit='s')\n",
    "df['ReviewLength'] = df['Text'].str.len()\n",
    "df['Year'] = df['Time'].dt.year\n",
    "df['Month'] = df['Time'].dt.month\n",
    "\n",
    "print(\"\\nPrimeras 5 filas del dataset procesado:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c6b62",
   "metadata": {},
   "source": [
    "### 2. Análisis de distribución de puntuaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fe8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear gráfico de distribución de puntuaciones\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='Score')\n",
    "plt.title('Distribución de Puntuaciones')\n",
    "plt.xlabel('Puntuación')\n",
    "plt.ylabel('Cantidad de Reseñas')\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas descriptivas de las puntuaciones\n",
    "print(\"Estadísticas descriptivas de las puntuaciones:\")\n",
    "print(df['Score'].describe())\n",
    "\n",
    "# Calcular porcentajes por puntuación\n",
    "score_percentages = (df['Score'].value_counts() / len(df) * 100).round(2)\n",
    "print(\"\\nPorcentaje de reseñas por puntuación:\")\n",
    "print(score_percentages.sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea3b7f",
   "metadata": {},
   "source": [
    "### 3. Patrones temporales en las reseñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d768520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolución de puntuaciones promedio por mes/año\n",
    "monthly_scores = df.groupby(['Year', 'Month'])['Score'].mean().reset_index()\n",
    "monthly_scores['Date'] = pd.to_datetime(monthly_scores[['Year', 'Month']].assign(DAY=1))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_scores['Date'], monthly_scores['Score'])\n",
    "plt.title('Evolución de Puntuaciones Promedio por Mes')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Puntuación Promedio')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Cambios en la longitud de las reseñas\n",
    "monthly_lengths = df.groupby(['Year', 'Month'])['ReviewLength'].mean().reset_index()\n",
    "monthly_lengths['Date'] = pd.to_datetime(monthly_lengths[['Year', 'Month']].assign(DAY=1))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_lengths['Date'], monthly_lengths['ReviewLength'])\n",
    "plt.title('Evolución de la Longitud Promedio de Reseñas por Mes')\n",
    "plt.xlabel('Fecha')\n",
    "plt.ylabel('Longitud Promedio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b244e0",
   "metadata": {},
   "source": [
    "### 4. Análisis por categoría de producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un análisis básico por ProductId\n",
    "product_analysis = df.groupby('ProductId').agg({\n",
    "'Score': ['mean', 'count'],\n",
    "'ReviewLength': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "product_analysis.columns = ['Puntuación_Promedio', 'Cantidad_Reseñas', 'Longitud_Promedio']\n",
    "product_analysis = product_analysis.reset_index()\n",
    "\n",
    "# Mostrar productos más reseñados\n",
    "print(\"Top 10 productos más reseñados:\")\n",
    "print(product_analysis.nlargest(10, 'Cantidad_Reseñas'))\n",
    "\n",
    "# Visualizar relación entre cantidad de reseñas y puntuación promedio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(product_analysis['Cantidad_Reseñas'], \n",
    "           product_analysis['Puntuación_Promedio'], \n",
    "           alpha=0.5)\n",
    "plt.title('Relación entre Cantidad de Reseñas y Puntuación Promedio')\n",
    "plt.xlabel('Cantidad de Reseñas')\n",
    "plt.ylabel('Puntuación Promedio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d79c5c1",
   "metadata": {},
   "source": [
    "### 5. Sistema de detección de reseñas potencialmente falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116e834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_suspicious_reviews(df):\n",
    "    # Crear características para detección\n",
    "    df['suspicious_score'] = 0\n",
    "    \n",
    "    # Crear columna de fecha\n",
    "    df['Date'] = df['Time'].dt.date  # Primero extraemos la fecha\n",
    "    \n",
    "    # 1. Reseñas extremadamente cortas o largas\n",
    "    length_quantiles = df['ReviewLength'].quantile([0.05, 0.95])\n",
    "    df.loc[df['ReviewLength'] < length_quantiles[0.05], 'suspicious_score'] += 1\n",
    "    df.loc[df['ReviewLength'] > length_quantiles[0.95], 'suspicious_score'] += 1\n",
    "\n",
    "    # 2. Usuario con muchas reseñas en poco tiempo\n",
    "    user_daily_reviews = df.groupby(['UserId', 'Date']).size().reset_index(name='daily_reviews')\n",
    "    suspicious_users = user_daily_reviews[user_daily_reviews['daily_reviews'] > 5]['UserId'].unique()\n",
    "    df.loc[df['UserId'].isin(suspicious_users), 'suspicious_score'] += 1\n",
    "\n",
    "    # 3. Puntuaciones extremas (1 o 5) con texto corto\n",
    "    df.loc[(df['Score'].isin([1, 5])) & (df['ReviewLength'] < 50), 'suspicious_score'] += 1\n",
    "\n",
    "    # Clasificar reseñas como sospechosas si tienen un score alto\n",
    "    df['is_suspicious'] = df['suspicious_score'] >= 2\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplicar el sistema de detección\n",
    "df = detect_suspicious_reviews(df)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Porcentaje de reseñas sospechosas:\")\n",
    "print(f\"{(df['is_suspicious'].mean() * 100).round(2)}%\")\n",
    "\n",
    "# Analizar características de reseñas sospechosas vs no sospechosas\n",
    "suspicious_stats = df.groupby('is_suspicious').agg({\n",
    "    'Score': 'mean',\n",
    "    'ReviewLength': 'mean',\n",
    "    'ProductId': 'count'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nEstadísticas comparativas:\")\n",
    "print(suspicious_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c94dc5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96e15cac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
