{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1: Ajuste de Hiperparámetros con TensorBoard\n",
    "\n",
    "## Objetivo\n",
    "Desarrollar un modelo de red neuronal para clasificación binaria ajustando hiperparámetros y visualizar el proceso de entrenamiento usando TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga y Preprocesamiento de Datos\n",
    "Primero cargaremos el dataset de SMS spam y realizaremos el preprocesamiento necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cargar los datos\n",
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "texts = data['v2'].values\n",
    "labels = data['v1'].values\n",
    "\n",
    "# Codificar las etiquetas\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# Tokenización y padding\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "# División en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definición del Modelo Base\n",
    "Crearemos una función para construir el modelo con parámetros configurables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_model(learning_rate, architecture, activation):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(5000, 32, input_length=100),\n",
    "        tf.keras.layers.Dense(architecture[0], activation=activation),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(architecture[1], activation=activation),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuración de TensorBoard y Entrenamiento\n",
    "Configuraremos TensorBoard y entrenaremos diferentes modelos con distintas combinaciones de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Definir los hiperparámetros a probar\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "architectures = [(32, 16), (64, 32), (128, 64)]\n",
    "activations = ['relu', 'tanh']\n",
    "\n",
    "# Crear directorio para logs\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Entrenar diferentes modelos\n",
    "for lr in learning_rates:\n",
    "    for arch in architectures:\n",
    "        for act in activations:\n",
    "            # Crear nombre único para cada configuración\n",
    "            name = f\"lr_{lr}_arch_{arch[0]}_{arch[1]}_act_{act}\"\n",
    "            print(f\"Training model with configuration: {name}\")\n",
    "            \n",
    "            # Configurar TensorBoard callback\n",
    "            tensorboard_callback = TensorBoard(\n",
    "                log_dir=log_dir + \"/\" + name,\n",
    "                histogram_freq=1\n",
    "            )\n",
    "            \n",
    "            # Crear y entrenar el modelo\n",
    "            model = create_model(lr, arch, act)\n",
    "            \n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=10,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[tensorboard_callback]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualización en TensorBoard\n",
    "Para visualizar los resultados en TensorBoard, ejecuta el siguiente comando en una celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluación del Mejor Modelo\n",
    "Después de analizar los resultados en TensorBoard, podemos crear y evaluar el modelo con los mejores hiperparámetros encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Crear el mejor modelo (después de analizar resultados)\n",
    "best_lr = 0.001  # Ajustar según resultados\n",
    "best_architecture = (64, 32)  # Ajustar según resultados\n",
    "best_activation = 'relu'  # Ajustar según resultados\n",
    "\n",
    "best_model = create_model(best_lr, best_architecture, best_activation)\n",
    "\n",
    "# Entrenar el mejor modelo\n",
    "history = best_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}